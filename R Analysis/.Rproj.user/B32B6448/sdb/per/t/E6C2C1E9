{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Reverse Correlation Expt 2 Analysis\"\nautor: \"Patrick Laflamme\"\noutput: html_document\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(dplyr)\nlibrary(R.matlab)\nlibrary(ggplot2)\nlibrary(psych)\n```\n\n## Define Some Important Functions\n\n```{r Function Definitions}\nimport_PartData <- function(fileDir){\n  #get files in given path\n  files <- list.files(path = fileDir, \".csv\", full.names = T)\n  \n  #marker to create new dataframe\n  new <- T\n  \n  #do for each file in the directory\n  for(file in files){\n    \n    #read the file into a dataframe\n    data <- read.csv(file, row.names=NULL,stringsAsFactors = F,sep = ',')\n    \n    #if this is the first one, create an output dataframe\n    if(new){\n      outdata <- data\n      new <- F\n    }\n    else{\n      #otherwise append it to the existing dataframe\n      outdata <- rbind(outdata, data)\n    }\n    \n  }\n  \n  #column name housekeeping\n  age <- colnames(outdata)[2]\n  colnames(outdata)[2]<- colnames(outdata)[3]\n  colnames(outdata)[3]<- age\n  \n  #convert to factors and do some more datacleaning\n  outdata <- outdata %>% mutate(Answer = as.numeric(replace(Answer, Answer==\"NULL\", NA)), Repeat. = as.numeric(replace(Repeat., Repeat. != \"0\", \"1\")), Target_Type = as.factor(Target_Type), Experiment_Phase = as.factor(Experiment_Phase)) %>% as.data.frame()\n  \n  gender <- outdata$Age\n  outdata$Age <- outdata$Sex.2.male.3.female.4.other.\n  outdata$Sex.2.male.3.female.4.other. <- gender\n  \n  remove(gender)\n  \n  return(outdata)\n}\n\ncalculate_imageWise_correlations <- function(fileDir, partData, targetFile){\n  #find the .mat files in the given directory.\n  files <- list.files(fileDir, full.names = T, pattern = \".mat\")\n  \n  #get all of the IDs to search the files for\n  IDs <- as.character(unique(interaction(partData$Participant_Number, partData$Session_Number, sep=\"_\")))\n  \n  #Now load the targets before the loop. readMat is slow, let's do it as few times as possible.\n  targets <- readMat(targetFile)\n  \n  partData$RelevantImageWiseCorrelation <- NA\n  partData$nonRelevantImageWiseCorrelation <- NA\n  \n  #iterate through the IDs\n  for(ID in IDs){\n    \n    #convert ID to numbers for accessing PartData\n    ParticipantNumber <- as.numeric(strsplit(ID, \"_\")[[1]][1])\n    SessionNumber <- as.numeric(strsplit(ID, \"_\")[[1]][2])\n    TargetID <- as.numeric(unique(filter(partData, Participant_Number == ParticipantNumber, Session_Number == SessionNumber)$Target_Type))\n    \n    #select the relevant file.\n    file <- files[grep(paste(\"/\",ID,\".mat\",sep=''), files)]\n    \n    #load the relevant file.\n    data <- readMat(file)\n    \n    #Discard data that isn't useful\n    data <- array(aperm(data$whitenoise,c(2,1,3)), c(2500,2000))\n    \n    #load the appropriate target image into memory.\n    correctTargetImage <- array(t(targets[[TargetID]]), c(2500))\n    #incorrectTargetImage <- array(targets[[-TargetID]], c(2500))\n    \n    #now calculate the correlations\n    correctCorrelations <- apply(data, 2, cor, y=correctTargetImage)\n    #incorrectCorrelations <- apply(data, 2, cor, y=incorrectTargetImage)\n    \n    partData$RelevantImageWiseCorrelation[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase==\" experimental\"] <- correctCorrelations[partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase==\" experimental\"]]\n    \n  }\n  \n  return(partData)\n}\n\ncalculate_CI_correlations <- function(fileDir, partData, EXPNAME='EXP2'){\n  #find the .mat files in the given directory.\n  files <- list.files(fileDir, full.names = T, pattern = \".mat\")\n  \n  #get all of the IDs to search the files for\n  IDs <- as.character(unique(interaction(partData$Participant_Number, partData$Session_Number, sep=\"_\")))\n  \n  #iterate through the IDs\n  for(ID in IDs){\n    \n    #convert ID to numbers for accessing PartData\n    ParticipantNumber <- as.numeric(strsplit(ID, \"_\")[[1]][1])\n    SessionNumber <- as.numeric(strsplit(ID, \"_\")[[1]][2])\n    TargetID <- as.numeric(unique(filter(partData, Participant_Number == ParticipantNumber, Session_Number == SessionNumber)$Target_Type))\n    \n    #select the relevant file.\n    file <- files[grep(paste(\"/\",ID,\".mat\",sep=''), files)]\n    \n    #load the relevant file.\n    data <- readMat(file)\n    \n    #Discard data that isn't useful\n    data <- array(aperm(data$whitenoise,c(2,1,3)), c(2500,2000))\n    \n    data <- data[,partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase==\" experimental\"]]\n    \n    responses <- partData$Response[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase==\" experimental\"]*2 - 1\n    \n    data <- t(t(data) * responses)\n    \n    if(SessionNumber==1){\n      assign(paste0('image', ParticipantNumber), as.matrix(rowSums(data), nrow=1))\n    }\n    else{\n      assign(paste0('image', ParticipantNumber), cbind(get(paste0('image', ParticipantNumber)), as.matrix(rowSums(data), nrow=1)))\n    \n      toPNG <- imager::as.cimg(rowSums(get(paste0('image', ParticipantNumber))))\n      \n      imager::save.image(toPNG, file = paste0(\"CIs/\",EXPNAME,\"/\", ParticipantNumber, \".png\"))\n    }\n    \n  }\n  for(ID in IDs){\n    \n    #convert ID to numbers for accessing PartData\n    ParticipantNumber <- as.numeric(strsplit(ID, \"_\")[[1]][1])\n    SessionNumber <- as.numeric(strsplit(ID, \"_\")[[1]][2])\n    TargetID <- as.numeric(unique(filter(partData, Participant_Number == ParticipantNumber, Session_Number == SessionNumber)$Target_Type))\n    \n    #select the relevant file.\n    file <- files[grep(paste(\"/\",ID,\".mat\",sep=''), files)]\n    \n    #load the relevant file.\n    data <- readMat(file)\n    \n    #Discard data that isn't useful\n    data <- array(aperm(data$whitenoise,c(2,1,3)), c(2500,2000))\n      \n    #now calculate the correlations\n    CICorrelations <- apply(data, 2, cor, y=rowSums(get(paste0('image', ParticipantNumber))))\n    #incorrectCorrelations <- apply(data, 2, cor, y=incorrectTargetImage)\n    \n    partData$CIImageWiseCorrelation[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase==\" experimental\"] <- CICorrelations[partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase==\" experimental\"]]\n  \n  }\n  return(partData)\n}\n\ncalc_dprime <- function(data){\n  \n  pFAs <- summarise(group_by(filter(data, Answer==0), Participant_Number, Experiment_Phase), pFAs=mean(Response))\n  \n  pHIT <- summarise(group_by(filter(data, Answer==1), Participant_Number, Experiment_Phase), pHIT=mean(Response))\n  \n  output <- merge(pHIT, pFAs)\n  \n  output <- mutate(output, pHIT = plyr::mapvalues(pHIT, from = c(0, 1), to = c(1/(80*2), (80*2-1)/(80*2))), pFAs = plyr::mapvalues(pFAs, from = c(0, 1), to = c(1/(80*2), (80*2-1)/(80*2))))\n  \n  output <- mutate(output, dprime = qnorm(pHIT) - qnorm(pFAs), ln_beta = (qnorm(pFAs)**2 - qnorm(pHIT)**2)/2)\n  \n  return(output)\n}\n\n\n```\n\n## Import the Data and Add the Active v Passive designations.\n\nHere we will import the data, add the associated Active v Passive Designations, and then separate the training vs. experimental data.\n\n```{r Import Data}\n\nParticipantData <- import_PartData(\"/Volumes/Storage/Experiment_Data/Reverse_Correlation_EXP2/data/\")\n\nParticipantDataCorrelations <- calculate_imageWise_correlations(\"/Volumes/Storage/Experiment_Data/Reverse_Correlation_EXP2/data/\", ParticipantData, \"targets4.mat\")\n\nParticipantDataCorrelations <- calculate_CI_correlations(\"/Volumes/Storage/Experiment_Data/Reverse_Correlation_EXP2/data/\", ParticipantDataCorrelations, EXPNAME = 'EXP2')\n\nExperimentalData <- filter(ParticipantDataCorrelations, Experiment_Phase == \" experimental\")\n\nTrainingData <- filter(ParticipantDataCorrelations, Experiment_Phase != \" experimental\")\n\n```\n\n## Training Data Analysis\n\nFirst let's use our dprime function to calculate dprime for the hard and easy practice sessions. This will help us get an idea of who is good at this, and who is bad at it. It will also clearly identify who just didn't get it.\n\n```{r Training Data, warning=FALSE}\nTrainingDprimes <-calc_dprime(TrainingData)\n```\n\nLet's plot the results.\n\n### Dprime\n\n```{r Dprime Plot, echo=FALSE}\n#create the plot.\nplot(filter(TrainingDprimes, Experiment_Phase==' easy')$dprime, filter(TrainingDprimes, Experiment_Phase==' hard')$dprime, pch=16, xlab = 'Dprime in Easy Phase', ylab = \"Dprime in Hard Phase\")\n\n#add participant number labels to make it easier to identify outliers.\ntext(filter(TrainingDprimes, Experiment_Phase==' easy')$dprime - 0.08, filter(TrainingDprimes, Experiment_Phase==' hard')$dprime, labels = filter(TrainingDprimes, Experiment_Phase==' easy')$Participant_Number,cex = 0.5)\n\n```\n\n\n### P(hits)\n\n```{r pHIT Plot, echo=FALSE}\n#create the plot.\nplot(filter(TrainingDprimes, Experiment_Phase==' easy')$pHIT, filter(TrainingDprimes, Experiment_Phase==' hard')$pHIT, pch=16, xlab = 'P(hits) in Easy Phase', ylab = \"P(hits) in Hard Phase\")\n\n#add participant number labels to make it easier to identify outliers.\ntext(filter(TrainingDprimes, Experiment_Phase==' easy')$pHIT - 0.003, filter(TrainingDprimes, Experiment_Phase==' hard')$pHIT, labels = filter(TrainingDprimes, Experiment_Phase==' easy')$Participant_Number,cex = 0.5)\n\n```\n\n### Ph(false alarms)\n\n```{r pFAs Plot, echo=FALSE}\n#create the plot.\nplot(filter(TrainingDprimes, Experiment_Phase==' easy')$pFAs, filter(TrainingDprimes, Experiment_Phase==' hard')$pFAs, pch=16, xlab = 'P(FAs) in Easy Phase', ylab = \"P(FAs) in Hard Phase\")\n\n#add participant number labels to make it easier to identify outliers.\ntext(filter(TrainingDprimes, Experiment_Phase==' easy')$pFAs - 0.008, filter(TrainingDprimes, Experiment_Phase==' hard')$pFAs, labels = filter(TrainingDprimes, Experiment_Phase==' easy')$Participant_Number,cex = 0.5)\n\n```\n\n\n### ln(Beta)\n\n```{r ln(Beta) Plot, echo=FALSE}\n#create the plot.\nplot(filter(TrainingDprimes, Experiment_Phase==' easy')$ln_beta, filter(TrainingDprimes, Experiment_Phase==' hard')$ln_beta, pch=16, xlab = 'ln(Beta) in Easy Phase', ylab = \"ln(Beta) in Hard Phase\")\n\n#add participant number labels to make it easier to identify outliers.\ntext(filter(TrainingDprimes, Experiment_Phase==' easy')$ln_beta - 0.06, filter(TrainingDprimes, Experiment_Phase==' hard')$ln_beta, labels = filter(TrainingDprimes, Experiment_Phase==' easy')$Participant_Number,cex = 0.5)\n\n```\n\n### Coherent training phase summary\n\n```{r Report average training data values}\nSummary_Dprime_data <- summarise(group_by(TrainingDprimes, Experiment_Phase), MeanPhit = mean(pHIT), SEpHit = sd(pHIT)/sqrt(n()),  MeanpFAs = mean(pFAs), SEpFAs = sd(pFAs)/sqrt(n()),  Meandprime = mean(dprime), SEdprime = sd(dprime)/sqrt(n()), Meanln_beta = mean(ln_beta), SEln_beta = sd(ln_beta)/sqrt(n()))\n\n\nSummary_Dprime_data\n```\n\n### Dprime\n\n```{r Dprime summary plot}\n#make the bars slightly separated for visual pleasure\ndodge <- position_dodge(width = 0.5)\n\n#define the error bar limits\nlimits <- aes(ymax = Summary_Dprime_data$Meandprime + Summary_Dprime_data$SEdprime,\n              ymin = Summary_Dprime_data$Meandprime - Summary_Dprime_data$SEdprime)\n\n#start the plot\np <- ggplot(data =Summary_Dprime_data, aes(x = Experiment_Phase, y = Meandprime))\n\n#now fill the plot\ndprimePlot <- p + geom_bar(stat = \"identity\", position = dodge) +\n  geom_errorbar(limits, position = dodge, width = 0.25) +\n  theme_bw() +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(y = \"Dprime\")+\n  ggtitle(\"Dprime by Experiment Phase\") +\n  ylim(0,4.5)\n\n#clean up the environment.\nremove(p, dodge, limits)\n\n```\n\n\n### ln_beta\n\n```{r ln_beta summary plot}\n#make the bars slightly separated for visual pleasure\ndodge <- position_dodge(width = 0.5)\n\n#define the error bar limits\nlimits <- aes(ymax = Summary_Dprime_data$Meanln_beta + Summary_Dprime_data$SEln_beta,\n              ymin = Summary_Dprime_data$Meanln_beta - Summary_Dprime_data$SEln_beta)\n\n#start the plot\np <- ggplot(data =Summary_Dprime_data, aes(x = Experiment_Phase, y = Meanln_beta))\n\n#now fill the plot\nln_betaPlot <- p + geom_bar(stat = \"identity\", position = dodge) +\n  geom_errorbar(limits, position = dodge, width = 0.25) +\n  theme_bw() +\n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+\n  labs(y = \"Log(Beta)\")+\n  ggtitle(\"Log(Beta) by Experiment Phase\") +\n  ylim(-1.5,1.5)\n\n#clean up the environment.\nremove(p, dodge, limits)\n\n```\n\n## Experimental Data Summary\n\n```{r Summarize Experimental Phase}\nExperimental_Summary_Overall <- summarise(ExperimentalData, meanAge = mean(Age), sdAge = sd(Age), propYes = mean(Response), maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n())\n\n Experimental_Summary_byPRTCPNT <- summarise(group_by(ExperimentalData, Participant_Number), propYes = mean(Response), numYes = sum(Response), maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n(), TotalTime = sum(RT)/60)\n\nExperimental_Summary_byTRGT <- summarise(group_by(ExperimentalData, Target_Type), propYes = mean(Response), maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n(), total_ptpts = length(unique(Participant_Number)))\n\n```\n\n### Overall summary\n```{r Experimental Results Overall}\n\nExperimental_Summary_Overall\n\n```\n\nIt seems as though the overall proportion of yes's is as expected. Max RT is pretty high. Let's take a look at the distribution of RTs.\n\n```{r Overall RT plot, echo = FALSE}\nhist(ExperimentalData$RT, breaks = 1000, main = \"Histogram of overall RT.\", xlab = 'RT')\n```\n\nThis looks good. Skewed shape as expected. Perhaps we should determine a timing cutoff?\n\n## Analysis of the Image-Wise correlations with CI and Prediction\n\nFirst step: aggregate likelihood of image being chosen as a \"yes\" given its correlation with the target.\n\n```{r CI Image-Wise Aggregate}\n#tag the images with similar IW correlations to group them later for aggregation\nExperimentalData_CI <- mutate(ExperimentalData, RelIWCorGroup = cut(CIImageWiseCorrelation, quantile(CIImageWiseCorrelation,p = seq(0,1,length.out = 400), na.rm = T)))\n\n#use the RelIWCorGroup above to calculate probYes for each range of IW corrrelation\nExperimental_Summary_byRelIWCor_CI <- summarise(group_by(ExperimentalData_CI, RelIWCorGroup), IWcor = mean(CIImageWiseCorrelation), pYes = mean(Response))\n```\n\nNow let's go ahead and do the scatter plots so get an idea of the relationships before we do the formal stats. Here we can also identify outliers. \n\n```{r CI IWCor-pYes scatter}\n\nwith(filter(Experimental_Summary_byRelIWCor_CI), plot(IWcor, pYes, pch=16, cex=0.5, xlab = \"Image-wise correlation between trial image and classification image\", ylab = \"Proportion of \\\"yes\\\" responses by participants\"))\n\n```\n\nNow we can go ahead and calculate the correlations here.\n\n```{r CI Correlations between Image-Wise correlation and probability of Yes}\nprint(\"Correlation:\")\nwith(Experimental_Summary_byRelIWCor_CI, cor.test(pYes,IWcor))\n\n```\n\n\n```{r CI Analysis Image-Wise Cor Plot, echo=FALSE}\nwith(Experimental_Summary_byRelIWCor_CI, plot(IWcor, pYes, pch=16, cex=0.5, ylim = c(0,1), ylab = \"Proportion of \\\"yes\\\" responses by participants\", xlab = \"Image-wise correlation between trial image and classification image\"))\nwith(Experimental_Summary_byRelIWCor_CI, abline(lm(pYes ~ IWcor)))\n\n```\n\n\n\n## Analysis of the Image-Wise correlations and Prediction\n\nFirst step: aggregate likelihood of image being chosen as a \"yes\" given its correlation with the target.\n\n```{r Image-Wise Aggregate}\n#tag the images with similar IW correlations to group them later for aggregation\nExperimentalData <- mutate(ExperimentalData, RelIWCorGroup = cut(RelevantImageWiseCorrelation, quantile(RelevantImageWiseCorrelation,p = seq(0,1,length.out = 400), na.rm = T)))\n\n#use the RelIWCorGroup above to calculate probYes for each range of IW corrrelation\nExperimental_Summary_byRelIWCor <- summarise(group_by(ExperimentalData, RelIWCorGroup), IWcor = mean(RelevantImageWiseCorrelation), pYes = mean(Response))\n```\n\nNow let's go ahead and do the scatter plots so get an idea of the relationships before we do the formal stats. Here we can also identify outliers. \n\n```{r IWCor-pYes scatter}\n\nwith(filter(Experimental_Summary_byRelIWCor), plot(IWcor, pYes, pch=16, cex=0.5))\n\n```\n\n\nMuch better. Now we can go ahead and calculate the correlations here.\n\n```{r Correlations between Image-Wise correlation and probability of Yes}\nprint(\"Correlation:\")\nwith(filter(Experimental_Summary_byRelIWCor, !is.na(RelIWCorGroup)), cor.test(pYes,IWcor))\n\n```\n\n```{r Analysis Image-Wise Cor Plot, echo=FALSE}\nwith(filter(Experimental_Summary_byRelIWCor, !is.na(RelIWCorGroup)), plot(IWcor, pYes, pch=16, cex=0.5, ylab = \"Proportion of \\\"yes\\\" responses by participants\", xlab = \"Image-wise correlation between trial image and target image\"))\nwith(filter(Experimental_Summary_byRelIWCor, !is.na(RelIWCorGroup)), abline(lm(pYes ~ IWcor)))\n\n```\n\n",
    "created" : 1485206224892.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "17|37|57|0|\n59|76|102|0|\n104|73|170|0|\n172|30|185|0|\n",
    "hash" : "3608742263",
    "id" : "E6C2C1E9",
    "lastKnownWriteTime" : 1486170418,
    "last_content_update" : 1486170418016,
    "path" : "~/Dropbox/Reverse_Correlation/R Analysis/Experiment 2 Analysis.Rmd",
    "project_path" : "Experiment 2 Analysis.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}