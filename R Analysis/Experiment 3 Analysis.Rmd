---
title: "Reverse Correlation Expt 3 Analysis"
autor: "Patrick Laflamme"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(R.matlab)
library(ggplot2)
library(psych)
library(cowplot)
```

## Define Some Important Functions

```{r Function Definitions}
import_PartData <- function(fileDir){
  #get files in given path
  files <- list.files(path = fileDir, ".csv", full.names = T)
  
  #marker to create new dataframe
  new <- T
  
  #do for each file in the directory
  for(file in files){
    
    #read the file into a dataframe
    data <- read.csv(file, row.names=NULL,stringsAsFactors = F)
    
    #if this is the first one, create an output dataframe
    if(new){
      outdata <- data
      new <- F
    }
    else{
      #otherwise append it to the existing dataframe
      outdata <- rbind(outdata, data)
    }
    
  }
  
  #column name housekeeping
  age <- colnames(outdata)[2]
  colnames(outdata)[2]<- colnames(outdata)[3]
  colnames(outdata)[3]<- age
  
  #convert to factors and do some more datacleaning
  outdata <- outdata %>% mutate(Answer = as.numeric(replace(Answer, Answer=="NULL", NA)), Repeat. = as.numeric(replace(Repeat., Repeat. != "0", "1")), Target_Type = as.factor(Target_Type), Experiment_Phase = as.factor(Experiment_Phase)) %>% as.data.frame()
  
  #Response is reverse coded, so fix that.
  outdata <- outdata %>% mutate(Response = as.numeric(Response)*-1 + 1) %>% as.data.frame()
  
  #create the condition variable - forgot to add to code (oops! - good thing we recorded it by hand too)
  ActiveVPassive <- list("1"="Active", "2"="Active", "3"="Passive","4"="Passive", "5"="Active", "6"="Active","7"="Passive", "8"="Passive", "9"="Active", "10"="Active", "11"="Passive", "12"="Passive", "13"="Active", "14"="Active", "15"="Passive", "16"="Passive", "17"="Active", "18"="Active")
  
  outdata <- mutate(outdata, Condition = unlist(ActiveVPassive[Participant_Number]))
  
  outdata$Condition <- as.factor(outdata$Condition)
  
  return(outdata)
}

calculate_imageWise_correlations <- function(fileDir, partData, targetFile){
  #find the .mat files in the given directory.
  files <- list.files(fileDir, full.names = T, pattern = ".mat")
  
  #get all of the IDs to search the files for
  IDs <- as.character(unique(interaction(partData$Participant_Number, partData$Session_Number, sep="_")))
  
  #Now load the targets before the loop. readMat is slow, let's do it as few times as possible.
  targets <- readMat(targetFile)
  
  partData$RelevantImageWiseCorrelation <- NA
  partData$nonRelevantImageWiseCorrelation <- NA
  
  #iterate through the IDs
  for(ID in IDs){
    
    #convert ID to numbers for accessing PartData
    ParticipantNumber <- as.numeric(strsplit(ID, "_")[[1]][1])
    SessionNumber <- as.numeric(strsplit(ID, "_")[[1]][2])
    TargetID <- as.numeric(unique(filter(partData, Participant_Number == ParticipantNumber, Session_Number == SessionNumber)$Target_Type))
    
    #select the relevant file.
    file <- files[grep(paste("/",ID,".mat",sep=''), files)]
    
    #load the relevant file.
    data <- readMat(file)
    
    #Discard data that isn't useful
    data <- array(aperm(data$whitenoise[,,1:500], c(2,1,3)), c(2500,500))
    
    #load the appropriate target image into memory.
    correctTargetImage <- array(t(targets[[TargetID]]), c(2500))
    incorrectTargetImage <- array(targets[[-TargetID]], c(2500))
    
    #now calculate the correlations
    correctCorrelations <- apply(data, 2, cor, y=correctTargetImage)
    incorrectCorrelations <- apply(data, 2, cor, y=incorrectTargetImage)
    
    partData$RelevantImageWiseCorrelation[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"] <- correctCorrelations[partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"]]
    
    partData$nonRelevantImageWiseCorrelation[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"] <- incorrectCorrelations[partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"]]
    
    
  }
  
  return(partData)
}

calculate_CI_correlations <- function(fileDir, partData, EXPNAME='EXP2'){
  #find the .mat files in the given directory.
  files <- list.files(fileDir, full.names = T, pattern = ".mat")
  
  #get all of the IDs to search the files for
  IDs <- as.character(unique(interaction(partData$Participant_Number, partData$Session_Number, sep="_")))
  
  #iterate through the IDs
  for(ID in IDs){
    
    #convert ID to numbers for accessing PartData
    ParticipantNumber <- as.numeric(strsplit(ID, "_")[[1]][1])
    SessionNumber <- as.numeric(strsplit(ID, "_")[[1]][2])
    TargetID <- as.numeric(unique(filter(partData, Participant_Number == ParticipantNumber, Session_Number == SessionNumber)$Target_Type))
    
    #select the relevant file.
    file <- files[grep(paste("/",ID,".mat",sep=''), files)]
    
    #load the relevant file.
    data <- readMat(file)
    
    #Discard data that isn't useful
    data <- array(aperm(data$whitenoise,c(2,1,3)), c(2500,2000))
    
    data <- data[,partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"]]
    
    responses <- partData$Response[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"]*2 - 1
    
    data <- t(t(data) * responses)
    
    if(SessionNumber==1){
      assign(paste0('image', ParticipantNumber), as.matrix(rowSums(data), nrow=1))
    }
    else{
      assign(paste0('image', ParticipantNumber), cbind(get(paste0('image', ParticipantNumber)), as.matrix(rowSums(data), nrow=1)))
      
      toPNG <- imager::as.cimg(rowSums(get(paste0('image', ParticipantNumber))))
      
      imager::save.image(toPNG, file = paste0("CIs/",EXPNAME,"/", ParticipantNumber, ".png"))
    }
    
  }
  
  for(ID in IDs){
    
    #convert ID to numbers for accessing PartData
    ParticipantNumber <- as.numeric(strsplit(ID, "_")[[1]][1])
    SessionNumber <- as.numeric(strsplit(ID, "_")[[1]][2])
    TargetID <- as.numeric(unique(filter(partData, Participant_Number == ParticipantNumber, Session_Number == SessionNumber)$Target_Type))
    
    #select the relevant file.
    file <- files[grep(paste("/",ID,".mat",sep=''), files)]
    
    #load the relevant file.
    data <- readMat(file)
    
    #Discard data that isn't useful
    data <- array(aperm(data$whitenoise,c(2,1,3)), c(2500,2000))
    
    #now calculate the correlations
    CICorrelations <- apply(data, 2, cor, y=rowSums(get(paste0('image', ParticipantNumber))))
    #incorrectCorrelations <- apply(data, 2, cor, y=incorrectTargetImage)
    
    partData$CIImageWiseCorrelation[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"] <- CICorrelations[partData$Trial_Number[partData$Participant_Number==ParticipantNumber & partData$Session_Number==SessionNumber & partData$Experiment_Phase=="experimental"]]
    
  }
  return(partData)
}

calc_dprime <- function(data){
  
  pFAs <- summarise(group_by(filter(data, Answer==0), Participant_Number, Experiment_Phase, Condition), pFAs=mean(Response))
  
  pHIT <- summarise(group_by(filter(data, Answer==1), Participant_Number, Experiment_Phase), pHIT=mean(Response))
  
  output <- merge(pHIT, pFAs)
  
  output <- mutate(output, pHIT = plyr::mapvalues(pHIT, from = c(0, 1), to = c(1/(80*2), (80*2-1)/(80*2))), pFAs = plyr::mapvalues(pFAs, from = c(0, 1), to = c(1/(80*2), (80*2-1)/(80*2))))
  
  output <- mutate(output, dprime = qnorm(pHIT) - qnorm(pFAs), ln_beta = (qnorm(pFAs)**2 - qnorm(pHIT)**2)/2)
  
  return(output)
}


```

## Import the Data and Add the Active v Passive designations.

Here we will import the data, add the associated Active v Passive Designations, and then separate the training vs. experimental data.

```{r Import Data}

ParticipantData <- import_PartData("EXP3_csv_data/")

ParticipantDataCorrelations <- calculate_imageWise_correlations("/Volumes/Storage/Experiment_Data/Reverse_Correlation_EXP3", ParticipantData, "targets.mat")

ParticipantDataCorrelations <- calculate_CI_correlations("/Volumes/Storage/Experiment_Data/Reverse_Correlation_EXP3", ParticipantDataCorrelations, EXPNAME = 'EXP3')

ExperimentalData <- filter(ParticipantDataCorrelations, Experiment_Phase == "experimental")

TrainingData <- filter(ParticipantDataCorrelations, Experiment_Phase != "experimental")

```

## Training Data Analysis

First let's use our dprime function to calculate dprime for the hard and easy practice sessions. This will help us get an idea of who is good at this, and who is bad at it. It will also clearly identify who just didn't get it.

```{r Training Data, warning=FALSE}
TrainingDprimes <-calc_dprime(TrainingData)
```

Let's plot the results.

### Dprime

```{r Dprime Plot, echo=FALSE}
#create the plot.
plot(filter(TrainingDprimes, Experiment_Phase=='easy')$dprime, filter(TrainingDprimes, Experiment_Phase=='hard')$dprime, pch=16, xlab = 'Dprime in Easy Phase', ylab = "Dprime in Hard Phase", col = c("black","blue")[filter(TrainingDprimes, Experiment_Phase=='easy')$Condition])

#add participant number labels to make it easier to identify outliers.
text(filter(TrainingDprimes, Experiment_Phase=='easy')$dprime - 0.1, filter(TrainingDprimes, Experiment_Phase=='hard')$dprime, labels = filter(TrainingDprimes, Experiment_Phase=='easy')$Participant_Number,cex = 0.5)

legend("topleft", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), pch = c(16,16), col = c('black', 'blue'))

```

Clearly, #9 didn't get the instructions. Somehow 1 and 6 didn't get it much either after the easy session.... 

### P(hits)

```{r pHIT Plot, echo=FALSE}
#create the plot.
plot(filter(TrainingDprimes, Experiment_Phase=='easy')$pHIT, filter(TrainingDprimes, Experiment_Phase=='hard')$pHIT, pch=16, xlab = 'P(hits) in Easy Phase', ylab = "P(hits) in Hard Phase", col = c("black","blue")[filter(TrainingDprimes, Experiment_Phase=='easy')$Condition])

#add participant number labels to make it easier to identify outliers.
text(filter(TrainingDprimes, Experiment_Phase=='easy')$pHIT - 0.01, filter(TrainingDprimes, Experiment_Phase=='hard')$pHIT, labels = filter(TrainingDprimes, Experiment_Phase=='easy')$Participant_Number,cex = 0.5)

legend("topleft", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), pch = c(16,16), col = c('black', 'blue'))

```

### Ph(false alarms)

```{r pFAs Plot, echo=FALSE}
#create the plot.
plot(filter(TrainingDprimes, Experiment_Phase=='easy')$pFAs, filter(TrainingDprimes, Experiment_Phase=='hard')$pFAs, pch=16, xlab = 'P(FAs) in Easy Phase', ylab = "P(FAs) in Hard Phase", col = c("black","blue")[filter(TrainingDprimes, Experiment_Phase=='easy')$Condition])

#add participant number labels to make it easier to identify outliers.
text(filter(TrainingDprimes, Experiment_Phase=='easy')$pFAs - 0.05, filter(TrainingDprimes, Experiment_Phase=='hard')$pFAs, labels = filter(TrainingDprimes, Experiment_Phase=='easy')$Participant_Number,cex = 0.5)

legend("topleft", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), pch = c(16,16), col = c('black', 'blue'))

```


### ln(Beta)

```{r ln(Beta) Plot, echo=FALSE}
#create the plot.
plot(filter(TrainingDprimes, Experiment_Phase=='easy')$ln_beta, filter(TrainingDprimes, Experiment_Phase=='hard')$ln_beta, pch=16, xlab = 'ln(Beta) in Easy Phase', ylab = "ln(Beta) in Hard Phase", col = c("black","blue")[filter(TrainingDprimes, Experiment_Phase=='easy')$Condition])

#add participant number labels to make it easier to identify outliers.
text(filter(TrainingDprimes, Experiment_Phase=='easy')$ln_beta - 0.1, filter(TrainingDprimes, Experiment_Phase=='hard')$ln_beta, labels = filter(TrainingDprimes, Experiment_Phase=='easy')$Participant_Number,cex = 0.5)

legend("topleft", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), pch = c(16,16), col = c('black', 'blue'))

```

## Coherent training phase summary

```{r Report average training data values}
Summary_Dprime_data <- summarise(group_by(TrainingDprimes, Experiment_Phase, Condition), MeanPhit = mean(pHIT), SEpHit = sd(pHIT)/sqrt(n()),  MeanpFAs = mean(pFAs), SEpFAs = sd(pFAs)/sqrt(n()),  Meandprime = mean(dprime), SEdprime = sd(dprime)/sqrt(n()), Meanln_beta = mean(ln_beta), SEln_beta = sd(ln_beta)/sqrt(n()))


Summary_Dprime_data
```

### Dprime

```{r Dprime summary plot}
#make the bars slightly separated for visual pleasure
dodge <- position_dodge(width = 0.91)

#define the error bar limits
limits <- aes(ymax = Summary_Dprime_data$Meandprime + Summary_Dprime_data$SEdprime,
              ymin = Summary_Dprime_data$Meandprime - Summary_Dprime_data$SEdprime)

#start the plot
p <- ggplot(data =Summary_Dprime_data, aes(x = Experiment_Phase, y = Meandprime, fill = Condition))

#now fill the plot
dprimePlot <- p + geom_bar(stat = "identity", position = dodge) +
  geom_errorbar(limits, position = dodge, width = 0.25) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  labs(y = "Dprime")+
  ggtitle("Dprime by Experiment Phase") +
  guides(fill=FALSE) + 
  scale_fill_manual(values=c("red", "blue"))

#clean up the environment.
remove(p, dodge, limits)

```


### ln_beta

```{r ln_beta summary plot}
#make the bars slightly separated for visual pleasure
dodge <- position_dodge(width = 0.91)

#define the error bar limits
limits <- aes(ymax = Summary_Dprime_data$Meanln_beta + Summary_Dprime_data$SEln_beta,
              ymin = Summary_Dprime_data$Meanln_beta - Summary_Dprime_data$SEln_beta)

#start the plot
p <- ggplot(data =Summary_Dprime_data, aes(x = Experiment_Phase, y = Meanln_beta, fill = Condition))

#now fill the plot
ln_betaPlot <- p + geom_bar(stat = "identity", position = dodge) +
  geom_errorbar(limits, position = dodge, width = 0.25) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  labs(y = "Log(Beta)")+
  ggtitle("Log(Beta) by Experiment Phase") + 
  scale_fill_manual(values=c("red", "blue"))

#clean up the environment.
remove(p, dodge, limits)

plot_grid(dprimePlot, ln_betaPlot, rel_widths = c(1,1.5))

```


## Experimental Data Summary

```{r Summarize Experimental Phase}
Experimental_Summary_Overall <- summarise(ExperimentalData, meanAge = mean(Age), sdAge = sd(Age), propYes = mean(Response), maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n())

 Experimental_Summary_byPRTCPNT <- summarise(group_by(ExperimentalData, Participant_Number), propYes = mean(Response), numYes = sum(Response), maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n(), Condition = unique(Condition), TotalTime = sum(RT)/60)

Experimental_Summary_byTRGT <- summarise(group_by(ExperimentalData, Target_Type), propYes = mean(Response), maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n(), total_ptpts = length(unique(Participant_Number)))

Experimental_Summary_byCDTN <- summarise(group_by(ExperimentalData, Condition), propYes = mean(Response), numYes = sum(Response),maxRT = max(RT), minRT = min(RT), sdRT = sd(RT), meanRT = mean(RT), total_trials = n(), total_ptpts = length(unique(Participant_Number)))

```

### Overall summary
```{r Experimental Results Overall}

Experimental_Summary_Overall

```

It seems as though the overall proportion of yes's is as expected. Max RT is pretty high. Let's take a look at the distribution of RTs.

```{r Overall RT plot, echo = FALSE}
hist(ExperimentalData$RT, breaks = 1000, main = "Histogram of overall RT.", xlab = 'RT')
```

This looks good. Skewed shape as expected. Perhaps we should determine a timing cutoff?

In any case, let's take a look and see if there are RT differences between conditions.

### Summary between conditions.

```{r Experimental Results by Condition}

Experimental_Summary_byCDTN

```

This looks good. There seems to be fewer "yes" reponses in the the passive condition when compared to the active condition. 

Let's do a test of proportions to be sure.

```{r Plot of Porportions of Yess, echo=FALSE}
#calculcate the Standard error for the proportions
Experimental_Summary_byCDTN$se <- sum(sqrt((Experimental_Summary_byCDTN$propYes*(1 - Experimental_Summary_byCDTN$propYes))/Experimental_Summary_byCDTN$total_trials))

#make the bars slightly separated for visual pleasure
dodge <- position_dodge(width = 0.5)

#define the error bar limits
limits <- aes(ymax = Experimental_Summary_byCDTN$propYes + Experimental_Summary_byCDTN$se,
              ymin = Experimental_Summary_byCDTN$propYes - Experimental_Summary_byCDTN$se)

#start the plot
p <- ggplot(data =Experimental_Summary_byCDTN, aes(x = Condition, y = propYes))

#now fill the plot
p + geom_bar(stat = "identity", position = dodge) +
  geom_errorbar(limits, position = dodge, width = 0.25) +
  theme_bw() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())+
  labs(y = "Proportion of \"Yes\" responses")+
  ggtitle("Proportion of \"Yes\" responses by Condition")

#clean up the environment.
remove(p, dodge, limits)

```


```{r test of proportions of yess between Conditons}

prop.test(Experimental_Summary_byCDTN$numYes, Experimental_Summary_byCDTN$total_trials)

```

Sure enough, people seem more likely to superstitiously percieve when actively searching for the target. This is definitely worth investigating in other ways!


Also, RT seems to follow the expected outcome. Let's compare the histograms to be sure.

```{r by condition RT plot, echo = FALSE}

plot(density(filter(ExperimentalData, Condition == "Active")$RT), main = "Histogram of Active Condition RT.", xlab="RT", xlim = c(0,20), ylim=c(0,1.2))

lines(density(filter(ExperimentalData, Condition == "Passive")$RT), main = "Histogram of Passive Condition RT.", xlab="RT", xlim= c(0,20), ylim=c(0,1.2), col = 'blue')

legend("topright", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), lty = c(1,1), col = c('black', 'blue'))

```

A quick t-test confirms.

```{r RT condition-wise t-test}

t.test(RT ~ Condition, data = ExperimentalData)

```

## Analysis of the Image-Wise correlations CI and Prediction

First step: aggregate likelihood of image being chosen as a "yes" given its correlation with the target.

```{r CI Image-Wise Aggregate}
#tag the images with similar IW correlations to group them later for aggregation
ExperimentalData_CI <- mutate(ExperimentalData, RelIWCorGroup = cut(CIImageWiseCorrelation, quantile(CIImageWiseCorrelation,p = seq(0,1,length.out = 400))))

#use the RelIWCorGroup above to calculate probYes for each range of IW corrrelation
Experimental_Summary_byRelIWCor <- summarise(group_by(ExperimentalData_CI, RelIWCorGroup, Condition), IWcor = mean(CIImageWiseCorrelation), pYes = mean(Response))
```

Now let's go ahead and do the scatter plots so get an idea of the relationships before we do the formal stats. Here we can also identify outliers. 

```{r CI IWCor-pYes scatter}

par(mfrow=c(2,1))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Active"), plot(IWcor, pYes, pch=16, cex=0.5, main = "Active Condition"))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", is.na(RelIWCorGroup)), points(IWcor, pYes, pch=16, cex=0.5, col = 'red'))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), plot(IWcor, pYes, pch=16, cex=0.5, main = "Passive Condition"))

par(mfrow=c(1,1))

```

It looks like there's a pretty nasty outlier in the Active Condition (Highlighter in red). Let's remove that.

```{r CI IWCor-pYes scatter - removed Outliers}

par(mfrow=c(2,1))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), plot(IWcor, pYes, pch=16, cex=0.5, main = "Active Condition"))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), plot(IWcor, pYes, pch=16, cex=0.5, main = "Passive Condition"))

par(mfrow=c(1,1))

```

Much better. Now we can go ahead and calculate the correlations here.

```{r CI Correlations between Image-Wise correlation and probability of Yes}
print("Correlation for the Active Condition:")
with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), cor.test(pYes,IWcor))

print("Correlation for the Passive Condition:")
with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), cor.test(pYes,IWcor))
```

Wow, that's quite a story. People seem to superstitiously see more when actively searching, but they seem to be less correlated to the target they're looking for. That's pretty neat.

Let's just be sure. Let's test that there's a significant difference in correlation between the active and passive groups.

```{r CI Testing Statistical Significance of Active v. Passive Correlation}

Active <- with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), cor.test(pYes,IWcor))

Passive <- with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), cor.test(pYes,IWcor))

print(r.test(n=Active$parameter+2, n2 = Passive$parameter+2, r12 = Active$estimate, r34 = Passive$estimate))

remove(Active, Passive)
```

Good, that I is dotted. 

Let's plot them together to directly compare them. Lines of best fit are included and colour coded.

```{r CI Analysis Image-Wise Cor Plot, echo=FALSE}
with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), plot(IWcor, pYes, pch=16, cex=0.5, ylim = c(0,1), col = 'red', ylab = "Proportion of \"yes\" responses by participants", xlab = "Image-wise correlation between trial image and target image"))
with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), abline(lm(pYes ~ IWcor), col = 'red'))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), points(IWcor, pYes, pch=16, cex=0.5, col='blue'))
with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), abline(lm(pYes ~ IWcor), col='blue'))

legend("topright", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), pch = c(15,15), pt.cex = c(2,2), col = c('red', 'blue'))
```




## Analysis of the Image-Wise correlations and Prediction

First step: aggregate likelihood of image being chosen as a "yes" given its correlation with the target.

```{r Image-Wise Aggregate}
#tag the images with similar IW correlations to group them later for aggregation
ExperimentalData <- mutate(ExperimentalData, RelIWCorGroup = cut(RelevantImageWiseCorrelation, quantile(RelevantImageWiseCorrelation,p = seq(0,1,length.out = 400))))

#use the RelIWCorGroup above to calculate probYes for each range of IW corrrelation
Experimental_Summary_byRelIWCor <- summarise(group_by(ExperimentalData, RelIWCorGroup, Condition), IWcor = mean(RelevantImageWiseCorrelation), pYes = mean(Response))
```

Now let's go ahead and do the scatter plots so get an idea of the relationships before we do the formal stats. Here we can also identify outliers. 

```{r IWCor-pYes scatter}

par(mfrow=c(2,1))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Active"), plot(IWcor, pYes, pch=16, cex=0.5, main = "Active Condition"))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", is.na(RelIWCorGroup)), points(IWcor, pYes, pch=16, cex=0.5, col = 'red'))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), plot(IWcor, pYes, pch=16, cex=0.5, main = "Passive Condition"))

par(mfrow=c(1,1))

```

It looks like there's a pretty nasty outlier in the Active Condition (Highlighter in red). Let's remove that.

```{r IWCor-pYes scatter - removed Outliers}

par(mfrow=c(2,1))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), plot(IWcor, pYes, pch=16, cex=0.5, main = "Active Condition"))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), plot(IWcor, pYes, pch=16, cex=0.5, main = "Passive Condition"))

par(mfrow=c(1,1))

```

Much better. Now we can go ahead and calculate the correlations here.

```{r Correlations between Image-Wise correlation and probability of Yes}
print("Correlation for the Active Condition:")
with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), cor.test(pYes,IWcor))

print("Correlation for the Passive Condition:")
with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), cor.test(pYes,IWcor))
```

Wow, that's quite a story. People seem to superstitiously see more when actively searching, but they seem to be less correlated to the target they're looking for. That's pretty neat.

Let's just be sure. Let's test that there's a significant difference in correlation between the active and passive groups.

```{r Testing Statistical Significance of Active v. Passive Correlation}

Active <- with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), cor.test(pYes,IWcor))

Passive <- with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), cor.test(pYes,IWcor))

print(r.test(n=Active$parameter+2, n2 = Passive$parameter+2, r12 = Active$estimate, r34 = Passive$estimate))

remove(Active, Passive)
```

Good, that I is dotted. 

Let's plot them together to directly compare them. Lines of best fit are included and colour coded.

```{r Analysis Image-Wise Cor Plot, echo=FALSE}
with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), plot(IWcor, pYes, pch=16, cex=0.5, ylim = c(0,1), col = 'red', ylab = "Proportion of \"yes\" responses by participants", xlab = "Image-wise correlation between trial image and target image"))
with(filter(Experimental_Summary_byRelIWCor,Condition=="Active", !is.na(RelIWCorGroup)), abline(lm(pYes ~ IWcor), col = 'red'))

with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), points(IWcor, pYes, pch=16, cex=0.5, col='blue'))
with(filter(Experimental_Summary_byRelIWCor,Condition=="Passive"), abline(lm(pYes ~ IWcor), col='blue'))

legend("topright", legend = levels(filter(TrainingDprimes, Experiment_Phase=='easy')$Condition), pch = c(15,15), pt.cex = c(2,2), col = c('red', 'blue'))
```

