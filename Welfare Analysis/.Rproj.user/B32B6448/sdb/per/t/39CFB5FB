{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Welfare Analysis\"\nauthor: \"Patrick Laflamme\"\ndate: \"December 21, 2016\"\noutput: \n  html_document: \n    fig_caption: yes\n    fig_height: 7\n    fig_width: 9\n---\n\ngenerate the anti-ci and make predictions with that.\n\n```{r setup, include=FALSE}\nlibrary(rcicr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(psych)\nlibrary(jpeg)\n\nload(\"4138635/R Materials for CIs/kp1_seed_NA_time_Jan_22_2015_12_24.Rdata\")\n\nscatterhist = function(x, y, xlab=\"\", ylab=\"\", ylim = NULL, xlim=NULL){\n  zones=matrix(c(1,0,3,2), ncol=2, byrow=TRUE)\n  layout(zones, widths=c(4/5,1/5), heights=c(1/5,4/5))\n  xhist = hist(x, plot=FALSE)\n  yhist = hist(y, plot=FALSE)\n  top = max(c(xhist$counts, yhist$counts))\n  par(mar=c(0,3,1,1))\n  barplot(xhist$counts, axes=FALSE, ylim=c(0, top), space=0)\n  par(mar=c(3,0,1,1))\n  barplot(yhist$counts, axes=FALSE, xlim=c(0, top), ylim = xlim, space=0, horiz=TRUE)\n  par(mar=c(3,3,1,1))\n  plot(x,y, ylim=ylim, xlim=xlim)\n  par(oma=c(3,3,0,0))\n  mtext(xlab, side=1, line=1, outer=TRUE, adj=0, \n    at=.6 * (mean(x) - min(x))/(max(x)-min(x)))\n  mtext(ylab, side=2, line=1, outer=TRUE, adj=0, \n    at=(.6 * (mean(y) - min(y))/(max(y) - min(y))))\n}\n\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Background\n\nThe goal here is to predict the probability of the generated image being selected as a welfare recipient. We derive the probability of being chosen by taking the proportion of responses from all participants in each study. \n\n## Internal Analyses\n\nLet's start by making internal predictions - (eg. using study 1 CI to predict study 1 data). This is to check if there is anything to this prediction at all.\n\n### Study 1\n\n```{r Loading the Study 1 data}\n#--------------------\n#---- Study 1 -------\n#--------------------\n\nwelfaredata1 <- read.csv(\"Study1_ReverseCorrelationDataLongForm_codedmissingvalues.csv\")\n\n# Recode responses\n# 1 = Positive stim\n# 0 = Negative stim\nwelfaredata1$response <- (welfaredata1$response * 2) - 1\n\n# Indicate repeated trials (pic > 400)\nwelfaredata1 <- subset(welfaredata1, pic <= 400)\n\n#load the CI and antiCI for the data\nCI1 <- matrix(imager::load.image(\"./cis/Study1_CI.jpg\"), nrow=512)\n\n#create a storage variable for the correlation between the\n#positive noise stimulus and the CI\nposcor1 <- c()\n\n#create a storage variable for the correlation between the\n#negative noise stimulus and the CI\nnegcor1 <- c()\n\nfor(i in 0:399){\n  \n  pos <- matrix(imager::load.image(paste(\"MyGennedStims/kp1_0.994736842105263\", sprintf(\"%05d_ori.jpg\", i), sep='_')), nrow=512)\n  \n  neg <- matrix(imager::load.image(paste(\"MyGennedStims/kp1_0.994736842105263\", sprintf(\"%05d_inv.jpg\", i), sep='_')), nrow=512)\n  \n  poscor1 <- c(poscor1, cor(c(CI1), c(pos)))\n  \n  negcor1 <- c(negcor1, cor(c(CI1), c(neg)))\n}\n\n```\n\n### Internal Prediction of Study 1\n\nLet's test the predictive power of the correlation between each image and the probability of selection.\n\n```{r testing the internal predictive power}\n\nstimprams <- stimuli_params$pat3\n\n#group the welfare data by picture ID number. exclude any missing responses.\nwelfaregroup <- group_by(filter(welfaredata1, response %in% c(-1,1)), pic)\n\n#generate the CI.\navImdiff <- welfaregroup$response %*% do.call(rbind, replicate(121, as.matrix(stimprams), simplify=FALSE))[welfaredata1$response %in% c(-1,1),]\navImdiff <- avImdiff-min(avImdiff)\navImdiff <- avImdiff/max(avImdiff)\navImdiff <- avImdiff*2 -1\n\nsinusioudCorsdiff <- cor(t(avImdiff), t(stimprams))\n\nPyes <- summarise(welfaregroup, mean = mean(response*0.5+0.5))\n\ncor.test(t(sinusioudCorsdiff), Pyes$mean)\n```\n\nThere is a near perfect prediction of Selection Probility within Study 1. Blue line is line of best fit. Red line is at chance selection. \n\n```{r Internal Prediction of Study 1, echo=FALSE}\nplot(t(sinusioudCorsdiff), Pyes$mean, ylim = c(0,1), xlab = \"Image-CI correlation\", ylab = \"Probability of Selection\")\nabline(lm(Pyes$mean~t(sinusioudCorsdiff)), col='blue')\nabline(0.5,0, col='red')\ntext(x = -0.1, y = 0.05, labels = paste(\"r =\", round(cor(t(sinusioudCorsdiff), Pyes$mean), 2)))\ntitle(outer=\"Study1 - pred Welfare\")\n```\n\n### Study 2\n\nStudy 2 is split into two parts: in Part 1, participants selected welfare recipients, in Part 2, participants selected non-welfare recipients.\n\n```{r loading the Study 2 data}\n\nwelfaredata2a <- read.csv(\"Study2_ReverseCorrelations_Welfare_LongForm.csv\")\n\nwelfaredata2b <- read.csv(\"Study2_ReverseCorrelations_NonWelfare_LongForm.csv\")\n\n\n# Recode responses\n# 1 = Positive stim\n# 0 = Negative stim\nwelfaredata2a$response <- (welfaredata2a$response * 2) - 1\n\nwelfaredata2b$response <- (welfaredata2b$response * 2) - 1\n\n\n# Indicate repeated trials (pic > 400)\nwelfaredata2a <- subset(welfaredata2a, pic <= 400)\n\nwelfaredata2b <- subset(welfaredata2b, pic <= 400)\n\nCI2a <- matrix(imager::load.image(\"./cis/Study2_Welfare_CI.jpg\"), nrow=512)\n\nCI2b <- matrix(imager::load.image(\"./cis/Study2_nonWelfare_CI.jpg\"), nrow=512)\n\nposcor2a <- c()\nnegcor2a <- c()\n\nposcor2b <- c()\nnegcor2b <- c()\n\nfor(i in 0:399){\n  \n  pos <- matrix(imager::load.image(paste(\"MyGennedStims/kp1_0.994736842105263\", sprintf(\"%05d_ori.jpg\", i), sep='_')), nrow=512)\n  \n  neg <- matrix(imager::load.image(paste(\"MyGennedStims/kp1_0.994736842105263\", sprintf(\"%05d_inv.jpg\", i), sep='_')), nrow=512)\n  \n  poscor2a <- c(poscor2a, cor(c(CI2a), c(pos)))\n  \n  negcor2a <- c(negcor2a, cor(c(CI2a), c(neg)))\n  \n  poscor2b <- c(poscor2b, cor(c(CI2b), c(pos)))\n  \n  negcor2b <- c(negcor2b, cor(c(CI2b), c(neg)))\n}\n\n\n```\n\n#### Internal Prediction of Part 1\n\nHere we try to predict internally from part 1 of Study 2, where participants are told to identify the image that looks most like a welfare recipient.\n\n```{r testing the internal predictive power - Study2a}\n\n#group the welfare data by picture ID number. exclude any missing responses.\nwelfaregroup <- group_by(filter(welfaredata2a, response %in% c(-1,1)), pic)\n\n#generate the CI.\navImdiff <- welfaregroup$response %*% do.call(rbind, replicate(123, as.matrix(stimprams), simplify=FALSE))[welfaredata2a$response %in% c(-1,1),]\navImdiff <- avImdiff-min(avImdiff)\navImdiff <- avImdiff/max(avImdiff)\navImdiff <- avImdiff*2 -1\n\nsinusioudCorsdiff2a <- cor(t(avImdiff), t(stimprams))\n\nPyes2a <- summarise(welfaregroup, mean = mean(response*0.5+0.5))\n\ncor.test(t(sinusioudCorsdiff2a), Pyes2a$mean)\n```\n\nAs in study 1, the predictive capabilities are really high (a near perfect correlation between the similarity between image and CI and probability of selection).\n\n```{r Internal Prediction of Study 2a, echo=FALSE}\nplot(t(sinusioudCorsdiff2a), Pyes2a$mean, ylim = c(0,1), xlab = \"Image-CI correlation\", ylab = \"Probability of Selection\")\nabline(lm(Pyes2a$mean~t(sinusioudCorsdiff2a)), col='blue')\nabline(0.5,0, col='red')\ntext(x = -0.1, y = 0.05, labels = paste(\"r =\", round(cor(t(sinusioudCorsdiff2a), Pyes2a$mean), 2)))\ntitle(outer=\"Study2 - pred Welfare\")\n```\n\n#### Internal Prediction of Part 2\n\n```{r testing the internal predictive power Study 2b}\n\n#group the welfare data by picture ID number. exclude any missing responses.\nwelfaregroup <- group_by(filter(welfaredata2b, response %in% c(-1,1)), pic)\n\n#generate the CI.\navImdiff <- welfaregroup$response %*% do.call(rbind, replicate(115, as.matrix(stimprams), simplify=FALSE))[welfaredata2b$response %in% c(-1,1),]\navImdiff <- avImdiff-min(avImdiff)\navImdiff <- avImdiff/max(avImdiff)\navImdiff <- avImdiff*2 -1\n\nsinusioudCorsdiff2b <- cor(t(avImdiff), t(stimprams))\n\nPyes2b <- summarise(welfaregroup, mean = mean(response*0.5+0.5))\n\ncor.test(t(sinusioudCorsdiff2b), Pyes2b$mean)\n```\n\nAs in Study 1 and in Part 1 of Study 2, we see an absurdly high correlation. This is because the CI depends on the data, and then we are prediction the data from the CI. \n\n```{r Internal Prediction of Study 2b, echo=FALSE}\nplot(t(sinusioudCorsdiff2b), Pyes2b$mean, ylim = c(0,1), xlab = \"Image-CI correlation\", ylab = \"Probability of Selection\")\nabline(lm(Pyes2b$mean~t(sinusioudCorsdiff2b)), col='blue')\nabline(0.5,0, col='red')\ntext(x = -0.1, y = 0.05, labels = paste(\"r =\", round(cor(t(sinusioudCorsdiff2b), Pyes2b$mean), 2)))\ntitle(outer=\"Study2 - pred non-Welfare\")\n```\n\nIn order to get around this and test things more realistically (less overfit) let's cross-test (predict study 2a with study 1 CI, study 2b with study 2a CI etc.). \n\n## External Analyses\n\nPredict the two Study 2 data sets with the Study 1 CI. Here we expect smaller R^2 than the internal predictions because there is less room for overfitting.\n\n### Predict with Study 1 CI\n\n#### Study 2a - Welfare\n```{r predicting Studies 2a (Welfare) from Study 1 CI}\ncor.test(t(sinusioudCorsdiff), Pyes2a$mean)\n```\n\nThe correlation seems to have switched directions. Is this a code error?\n\n```{r Predict Study 2a from Study 1 CI, echo=FALSE}\nplot(t(sinusioudCorsdiff), Pyes2a$mean, ylim = c(0,1), xlab = \"Image-CI correlation from Study 1\", ylab = \"Probability of Selection in Study 2a\")\nabline(lm(Pyes2a$mean~t(sinusioudCorsdiff)), col='blue')\nabline(0.5,0, col='red')\ntext(x = -0.1, y = 0.05, labels = paste(\"r =\", round(cor(t(sinusioudCorsdiff), Pyes2a$mean), 2)))\n```\n\n#### Study 2b - non-Welfare\n```{r predicting Studies 2b from Study 1 CI}\ncor.test(t(sinusioudCorsdiff), Pyes2b$mean)\n```\n\nSame here. There seems to be a reversal of the predicted direction. We would expect to see a positive correlation between Study 1 and Study 2a because the participants were supposed to be searching for the same thing. However, it seems that the relationship is negative. Now, looking at Study 2b, we would expect that the relationship would be negative, since participants in Study 2b did the opposite of what the participants in Study 1 did (Study 2b were looking for non-Welfare participants.)\n\n```{r Predict Study 2b from Study 1 CI, echo=FALSE}\nplot(t(sinusioudCorsdiff), Pyes2b$mean, ylim = c(0,1), xlab = \"Image-CI correlation from Study 1\", ylab = \"Probability of Selection in Study 2b\")\nabline(lm(Pyes2b$mean~t(sinusioudCorsdiff)), col='blue')\nabline(0.5,0, col='red')\ntext(x = -0.1, y = 0.05, labels = paste(\"r =\", round(cor(t(sinusioudCorsdiff), Pyes2b$mean), 2)))\n```\n\nWe can clearly see the relationships are in the wrong direction.\n\nSanity Check: What about predicting 2b with 2a. Here, we would predict a -ve correlation since these two were given opposite tasks as well.\n\n```{r predicting Study 2b from Study 2a CI}\ncor.test(t(sinusioudCorsdiff2a), Pyes2b$mean)\n```\n\nOkay we seem to have a relationship in the right direction on this one... So what happened with Study 1? Perhaps the Welfare and non-Welfare datasets are switched?\n\n```{r Predict Study 2b from Study 2a CI, echo=FALSE}\nplot(t(sinusioudCorsdiff2a), Pyes2b$mean, ylim = c(0,1), xlab = \"Image-CI correlation from Study 2a\", ylab = \"Probability of Selection in Study 2b\")\nabline(lm(Pyes2b$mean~t(sinusioudCorsdiff2a)), col='blue')\nabline(0.5,0, col='red')\ntext(x = -0.1, y = 0.05, labels = paste(\"r =\", round(cor(t(sinusioudCorsdiff2a), Pyes2b$mean), 2)))\n```\n\n",
    "created" : 1482343753832.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "24|71|41|0|\n",
    "hash" : "3409020403",
    "id" : "39CFB5FB",
    "lastKnownWriteTime" : 1484246401,
    "last_content_update" : 1484246401712,
    "path" : "~/Dropbox/Reverse_Correlation/Welfare Analysis/Analysis Markdown.Rmd",
    "project_path" : "Analysis Markdown.Rmd",
    "properties" : {
        "docOutlineVisible" : "1",
        "tempName" : "Untitled1"
    },
    "relative_order" : 6,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}